{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialising Spark Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"customerAnalysis\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Data Frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "columns = [\"timestamp_col\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"dataset/file1.csv\")\n",
    "df_2= spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"dataset/file2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1.union(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Invoice: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- Price: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------------+--------+------------+-----+----------+--------------+\n",
      "|Invoice|StockCode|         Description|Quantity| InvoiceDate|Price|CustomerID|       Country|\n",
      "+-------+---------+--------------------+--------+------------+-----+----------+--------------+\n",
      "| 489434|    85048|15CM CHRISTMAS GL...|      12|12/1/09 7:45| 6.95|     13085|United Kingdom|\n",
      "| 489434|   79323P|  PINK CHERRY LIGHTS|      12|12/1/09 7:45| 6.75|     13085|United Kingdom|\n",
      "| 489434|   79323W| WHITE CHERRY LIGHTS|      12|12/1/09 7:45| 6.75|     13085|United Kingdom|\n",
      "| 489434|    22041|\"RECORD FRAME 7\"\"...|      48|12/1/09 7:45|  2.1|     13085|United Kingdom|\n",
      "| 489434|    21232|STRAWBERRY CERAMI...|      24|12/1/09 7:45| 1.25|     13085|United Kingdom|\n",
      "| 489434|    22064|PINK DOUGHNUT TRI...|      24|12/1/09 7:45| 1.65|     13085|United Kingdom|\n",
      "| 489434|    21871| SAVE THE PLANET MUG|      24|12/1/09 7:45| 1.25|     13085|United Kingdom|\n",
      "| 489434|    21523|FANCY FONT HOME S...|      10|12/1/09 7:45| 5.95|     13085|United Kingdom|\n",
      "| 489435|    22350|           CAT BOWL |      12|12/1/09 7:46| 2.55|     13085|United Kingdom|\n",
      "| 489435|    22349|DOG BOWL , CHASIN...|      12|12/1/09 7:46| 3.75|     13085|United Kingdom|\n",
      "| 489435|    22195|HEART MEASURING S...|      24|12/1/09 7:46| 1.65|     13085|United Kingdom|\n",
      "| 489435|    22353|LUNCHBOX WITH CUT...|      12|12/1/09 7:46| 2.55|     13085|United Kingdom|\n",
      "| 489436|   48173C|DOOR MAT BLACK FL...|      10|12/1/09 9:06| 5.95|     13078|United Kingdom|\n",
      "| 489436|    21755|LOVE BUILDING BLO...|      18|12/1/09 9:06| 5.45|     13078|United Kingdom|\n",
      "| 489436|    21754|HOME BUILDING BLO...|       3|12/1/09 9:06| 5.95|     13078|United Kingdom|\n",
      "| 489436|    84879|ASSORTED COLOUR B...|      16|12/1/09 9:06| 1.69|     13078|United Kingdom|\n",
      "| 489436|    22119| PEACE WOODEN BLO...|       3|12/1/09 9:06| 6.95|     13078|United Kingdom|\n",
      "| 489436|    22142|CHRISTMAS CRAFT W...|      12|12/1/09 9:06| 1.45|     13078|United Kingdom|\n",
      "| 489436|    22296|HEART IVORY TRELL...|      12|12/1/09 9:06| 1.65|     13078|United Kingdom|\n",
      "| 489436|    22295|HEART FILIGREE DO...|      12|12/1/09 9:06| 1.65|     13078|United Kingdom|\n",
      "+-------+---------+--------------------+--------+------------+-----+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered=df.filter((col('Quantity')>0) & (col('Price')>0) & (col('CustomerID').isNotNull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------------+--------+------------+-----+----------+--------------+\n",
      "|Invoice|StockCode|         Description|Quantity| InvoiceDate|Price|CustomerID|       Country|\n",
      "+-------+---------+--------------------+--------+------------+-----+----------+--------------+\n",
      "| 489434|    85048|15CM CHRISTMAS GL...|      12|12/1/09 7:45| 6.95|     13085|United Kingdom|\n",
      "| 489434|   79323P|  PINK CHERRY LIGHTS|      12|12/1/09 7:45| 6.75|     13085|United Kingdom|\n",
      "| 489434|   79323W| WHITE CHERRY LIGHTS|      12|12/1/09 7:45| 6.75|     13085|United Kingdom|\n",
      "| 489434|    22041|\"RECORD FRAME 7\"\"...|      48|12/1/09 7:45|  2.1|     13085|United Kingdom|\n",
      "| 489434|    21232|STRAWBERRY CERAMI...|      24|12/1/09 7:45| 1.25|     13085|United Kingdom|\n",
      "| 489434|    22064|PINK DOUGHNUT TRI...|      24|12/1/09 7:45| 1.65|     13085|United Kingdom|\n",
      "| 489434|    21871| SAVE THE PLANET MUG|      24|12/1/09 7:45| 1.25|     13085|United Kingdom|\n",
      "| 489434|    21523|FANCY FONT HOME S...|      10|12/1/09 7:45| 5.95|     13085|United Kingdom|\n",
      "| 489435|    22350|           CAT BOWL |      12|12/1/09 7:46| 2.55|     13085|United Kingdom|\n",
      "| 489435|    22349|DOG BOWL , CHASIN...|      12|12/1/09 7:46| 3.75|     13085|United Kingdom|\n",
      "| 489435|    22195|HEART MEASURING S...|      24|12/1/09 7:46| 1.65|     13085|United Kingdom|\n",
      "| 489435|    22353|LUNCHBOX WITH CUT...|      12|12/1/09 7:46| 2.55|     13085|United Kingdom|\n",
      "| 489436|   48173C|DOOR MAT BLACK FL...|      10|12/1/09 9:06| 5.95|     13078|United Kingdom|\n",
      "| 489436|    21755|LOVE BUILDING BLO...|      18|12/1/09 9:06| 5.45|     13078|United Kingdom|\n",
      "| 489436|    21754|HOME BUILDING BLO...|       3|12/1/09 9:06| 5.95|     13078|United Kingdom|\n",
      "| 489436|    84879|ASSORTED COLOUR B...|      16|12/1/09 9:06| 1.69|     13078|United Kingdom|\n",
      "| 489436|    22119| PEACE WOODEN BLO...|       3|12/1/09 9:06| 6.95|     13078|United Kingdom|\n",
      "| 489436|    22142|CHRISTMAS CRAFT W...|      12|12/1/09 9:06| 1.45|     13078|United Kingdom|\n",
      "| 489436|    22296|HEART IVORY TRELL...|      12|12/1/09 9:06| 1.65|     13078|United Kingdom|\n",
      "| 489436|    22295|HEART FILIGREE DO...|      12|12/1/09 9:06| 1.65|     13078|United Kingdom|\n",
      "+-------+---------+--------------------+--------+------------+-----+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Spending Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "customer_spend_df = df_filtered.groupBy(\"CustomerID\").agg(\n",
    "    round(spark_sum(col(\"Quantity\") * col(\"Price\")), 2).alias(\"Total Spend\")\n",
    ")\n",
    "\n",
    "top_customers = customer_spend_df.orderBy(desc(\"Total Spend\")).limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|CustomerID|Total Spend|\n",
      "+----------+-----------+\n",
      "|     18102|  608821.65|\n",
      "|     14646|  528602.52|\n",
      "|     14156|  313946.37|\n",
      "|     14911|  295972.63|\n",
      "|     17450|  246973.09|\n",
      "|     13694|  196482.81|\n",
      "|     17511|  175603.55|\n",
      "|     16446|   168472.5|\n",
      "|     16684|  147142.77|\n",
      "|     12415|  144458.37|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top_customers.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequently Bought Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+\n",
      "|StockCode|FrequentlyBought|\n",
      "+---------+----------------+\n",
      "|    84077|          109169|\n",
      "|   85099B|           94983|\n",
      "|   85123A|           93697|\n",
      "|    21212|           91263|\n",
      "|    23843|           80995|\n",
      "|    84879|           79913|\n",
      "|    22197|           77971|\n",
      "|    23166|           77916|\n",
      "|    17003|           71129|\n",
      "|    21977|           55270|\n",
      "+---------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_FreqBought = df_filtered.groupBy('StockCode').agg(sum((col('Quantity'))).alias('FrequentlyBought'))\n",
    "top_products = df_FreqBought.orderBy(desc(\"FrequentlyBought\")).limit(10)\n",
    "top_products.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 344:===============================>                        (9 + 7) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|MonthYear|TotalSales|\n",
      "+---------+----------+\n",
      "|2009-12  |799847.11 |\n",
      "|2010-01  |624032.89 |\n",
      "|2010-02  |533091.43 |\n",
      "|2010-03  |765848.76 |\n",
      "|2010-04  |590580.43 |\n",
      "|2010-05  |615322.83 |\n",
      "|2010-06  |679786.61 |\n",
      "|2010-07  |575236.36 |\n",
      "|2010-08  |656776.34 |\n",
      "|2010-09  |853650.43 |\n",
      "|2010-10  |1045168.35|\n",
      "|2010-11  |1422654.64|\n",
      "|2010-12  |1126445.47|\n",
      "|2011-01  |560000.26 |\n",
      "|2011-02  |498062.65 |\n",
      "|2011-03  |683267.08 |\n",
      "|2011-04  |493207.12 |\n",
      "|2011-05  |723333.51 |\n",
      "|2011-06  |691123.12 |\n",
      "|2011-07  |681300.11 |\n",
      "|2011-08  |682680.51 |\n",
      "|2011-09  |1019687.62|\n",
      "|2011-10  |1070704.67|\n",
      "|2011-11  |1461756.25|\n",
      "|2011-12  |433686.01 |\n",
      "+---------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_timestamp, date_format, col, sum as spark_sum\n",
    "\n",
    "df = df.withColumn(\"InvoiceDate\", to_timestamp(col(\"InvoiceDate\"), \"M/d/yy H:mm\"))\n",
    "\n",
    "df = df.withColumn(\"MonthYear\", date_format(col(\"InvoiceDate\"), \"yyyy-MM\"))\n",
    "\n",
    "monthly_sales = df.groupBy(\"MonthYear\").agg(\n",
    "    round(spark_sum(col(\"Quantity\") * col(\"Price\")), 2).alias(\"TotalSales\")\n",
    ")\n",
    "\n",
    "monthly_sales = monthly_sales.orderBy(\"MonthYear\")\n",
    "\n",
    "monthly_sales.show(50, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yearly Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n",
      "|Year|TotalSales|\n",
      "+----+----------+\n",
      "|2009|799847.11 |\n",
      "|2010|9488594.54|\n",
      "|2011|8998808.91|\n",
      "+----+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_timestamp, col, sum as spark_sum, year\n",
    "\n",
    "df = df.withColumn(\"InvoiceDate\", to_timestamp(col(\"InvoiceDate\"), \"M/d/yy H:mm\"))\n",
    "\n",
    "df = df.withColumn(\"Year\", year(col(\"InvoiceDate\")))\n",
    "\n",
    "yearly_sales = df.groupBy(\"Year\").agg(\n",
    "    round(spark_sum(col(\"Quantity\") * col(\"Price\")), 2).alias(\"TotalSales\")\n",
    ").orderBy(\"Year\")\n",
    "\n",
    "yearly_sales.show(50, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales Per Store \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|Country    |TotalSales|\n",
      "+-----------+----------+\n",
      "|Sweden     |87809.42  |\n",
      "|Germany    |417988.56 |\n",
      "|France     |328191.8  |\n",
      "|Greece     |18995.49  |\n",
      "|Belgium    |63574.49  |\n",
      "|Finland    |29514.45  |\n",
      "|Nigeria    |-6.66     |\n",
      "|Unspecified|9687.32   |\n",
      "|Italy      |30679.35  |\n",
      "|EIRE       |615519.55 |\n",
      "+-----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "sales_per_store = df.groupBy(\"Country\").agg(\n",
    "    round(sum(col(\"Quantity\") * col(\"Price\")), 2).alias(\"TotalSales\")\n",
    ")\n",
    "\n",
    "sales_per_store.show(10, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Purchase Frequency \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|CustomerID|PurchaseFrequency|\n",
      "+----------+-----------------+\n",
      "|13623     |303              |\n",
      "|17679     |105              |\n",
      "|17389     |449              |\n",
      "|18051     |58               |\n",
      "|13289     |16               |\n",
      "|17753     |73               |\n",
      "|15727     |694              |\n",
      "|15967     |502              |\n",
      "|15254     |68               |\n",
      "|12471     |1298             |\n",
      "+----------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "customer_purchase_frequency = df.groupBy(\"CustomerID\").agg(\n",
    "    count(\"Invoice\").alias(\"PurchaseFrequency\")\n",
    ")\n",
    "\n",
    "customer_purchase_frequency.show(10, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Segmentation (RFM Analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 359:============================>                           (8 + 8) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---------+--------+\n",
      "|CustomerID|Recency|Frequency|Monetary|\n",
      "+----------+-------+---------+--------+\n",
      "|13623     |30     |303      |2446.36 |\n",
      "|17679     |52     |105      |3166.56 |\n",
      "|17389     |0      |449      |54587.03|\n",
      "|18051     |634    |58       |2275.98 |\n",
      "|13289     |723    |16       |307.95  |\n",
      "|17753     |464    |73       |388.06  |\n",
      "|15727     |16     |694      |9445.51 |\n",
      "|15967     |23     |502      |3019.2  |\n",
      "|15254     |127    |68       |1073.4  |\n",
      "|12471     |2      |1298     |37948.61|\n",
      "+----------+-------+---------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "latest_date = df.select(max(\"InvoiceDate\")).collect()[0][0]\n",
    "\n",
    "rfm_df = df.groupBy(\"CustomerID\").agg(\n",
    "    datediff(lit(latest_date), max(\"InvoiceDate\")).alias(\"Recency\"),\n",
    "    count(\"Invoice\").alias(\"Frequency\"),\n",
    "    round(sum(col(\"Quantity\") * col(\"Price\")), 2).alias(\"Monetary\")\n",
    ")\n",
    "\n",
    "rfm_df.show(10, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Country-wise Revenue Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+\n",
      "|       Country| TotalRevenue|\n",
      "+--------------+-------------+\n",
      "|United Kingdom|1.472314752E7|\n",
      "|          EIRE|    621631.11|\n",
      "|   Netherlands|    554232.34|\n",
      "|       Germany|    431262.46|\n",
      "|        France|    355257.47|\n",
      "|     Australia|    169968.11|\n",
      "|         Spain|    109178.53|\n",
      "|   Switzerland|    100365.34|\n",
      "|        Sweden|     91549.72|\n",
      "|       Denmark|     69862.19|\n",
      "+--------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_revenue_df = df_filtered.groupBy(\"Country\").agg(\n",
    "    round(sum(col(\"Quantity\") * col(\"Price\")), 2).alias(\"TotalRevenue\")\n",
    ")\n",
    "\n",
    "country_revenue_df.orderBy(desc(\"TotalRevenue\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Order Value (AOV) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 365:===============================>                        (9 + 7) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|AverageOrderValue|\n",
      "+-----------------+\n",
      "|           479.95|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "order_spend_df = df_filtered.groupBy(\"Invoice\").agg(\n",
    "    round(sum(col(\"Quantity\") * col(\"Price\")), 2).alias(\"OrderTotal\")\n",
    ")\n",
    "\n",
    "aov_df = order_spend_df.agg(round(avg(\"OrderTotal\"), 2).alias(\"AverageOrderValue\"))\n",
    "aov_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Processed Data in Parquet Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "customer_spend_df.write.mode(\"overwrite\").parquet(\"output/customer_spending.parquet\")\n",
    "top_products.write.mode(\"overwrite\").parquet(\"output/top_products.parquet\")\n",
    "monthly_sales.write.mode(\"overwrite\").parquet(\"output/monthly_sales.parquet\")\n",
    "yearly_sales.write.mode(\"overwrite\").parquet(\"output/yearly_sales.parquet\")\n",
    "customer_purchase_frequency.write.mode(\"overwrite\").parquet(\"output/purchase_frequency.parquet\")\n",
    "sales_per_store.write.mode(\"overwrite\").parquet(\"output/sales_per_store.parquet\")\n",
    "country_revenue_df.write.mode(\"overwrite\").parquet(\"output/country_revenue.parquet\")\n",
    "order_spend_df.write.mode(\"overwrite\").parquet(\"output/order_spend.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Pandas for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "top_customers_pd = top_customers.toPandas()\n",
    "top_products_pd = top_products.toPandas()\n",
    "monthly_sales_pd = monthly_sales.toPandas()\n",
    "yearly_sales_pd = yearly_sales.toPandas()\n",
    "sales_per_store_pd = sales_per_store.toPandas()\n",
    "purchase_frequency_pd = customer_purchase_frequency.toPandas()\n",
    "rfm_pd = rfm_df.toPandas()\n",
    "country_revenue_pd = country_revenue_df.toPandas().sort_values(\"TotalRevenue\", ascending=False).head(10)\n",
    "order_spend_pd = order_spend_df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Customers Spending Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(top_customers_pd['CustomerID'].astype(str), top_customers_pd['Total Spend'], color='skyblue')\n",
    "plt.xlabel(\"Customer ID\")\n",
    "plt.ylabel(\"Total Spending\")\n",
    "plt.title(\"Top 10 Customers by Total Spending\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Purchased Product Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(top_products_pd['StockCode'].astype(str), top_products_pd['FrequentlyBought'], color='skyblue')\n",
    "plt.xlabel(\"Stock Code\")\n",
    "plt.ylabel(\"Total Quantity Sold\")\n",
    "plt.title(\"Top 10 Most Purchased Products\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Sales Trend Visualization\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(monthly_sales_pd['MonthYear'], monthly_sales_pd['TotalSales'], marker='o', linestyle='-', color='skyblue')\n",
    "plt.xlabel(\"Month-Year\")\n",
    "plt.ylabel(\"Total Sales\")\n",
    "plt.title(\"Monthly Sales Trends\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yearly Sales Trend Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if \"TotalSalesYear\" not in yearly_sales_pd.columns:\n",
    "    yearly_sales_pd.rename(columns={\"TotalSales\": \"TotalSalesYear\"}, inplace=True)\n",
    "\n",
    "yearly_sales_pd['Year'] = yearly_sales_pd['Year'].astype(str)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.bar(yearly_sales_pd['Year'], yearly_sales_pd['TotalSalesYear'], color='skyblue')\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Total Sales\")\n",
    "plt.title(\"Yearly Sales Trends\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales Per Store Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.bar(sales_per_store_pd['Country'], sales_per_store_pd['TotalSales'], color='skyblue')\n",
    "plt.xlabel(\"Country\")\n",
    "plt.ylabel(\"Total Sales\")\n",
    "plt.title(\"Product Sales Per Store\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Purchase Frequency Visualization\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(purchase_frequency_pd['PurchaseFrequency'], bins=30, color='skyblue', edgecolor='black')\n",
    "plt.xlabel(\"Purchase Frequency\")\n",
    "plt.ylabel(\"Number of Customers\")\n",
    "plt.title(\"Customer Purchase Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Country-wise Revenue Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(country_revenue_pd[\"TotalRevenue\"], labels=country_revenue_pd[\"Country\"], autopct=\"%1.1f%%\", colors=plt.cm.Paired.colors)\n",
    "plt.title(\"Top 10 Countries by Revenue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order Values Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/04 20:20:02 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 727210 ms exceeds timeout 120000 ms\n",
      "25/04/04 20:20:02 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "25/04/04 20:20:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 20:20:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 20:20:17 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 20:20:17 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 20:38:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 20:38:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 20:38:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 20:38:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 20:38:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 20:38:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 21:10:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 21:10:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 21:21:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 21:21:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 21:52:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 21:52:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 21:52:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 21:52:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 21:52:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/04 21:52:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/04 21:53:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 21:53:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 22:22:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 22:22:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 22:38:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 22:38:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 22:55:37 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 22:55:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 22:55:47 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 22:55:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 22:55:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 22:55:57 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 23:11:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 23:11:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 23:23:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 23:23:10 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 23:39:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/04 23:39:00 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 00:10:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 00:10:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 00:11:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 00:11:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 00:11:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 00:11:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 00:11:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 00:11:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 00:42:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 00:42:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 01:14:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 01:14:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 01:14:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 01:14:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 01:14:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 01:14:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 01:14:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 01:14:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 01:25:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 01:25:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 01:57:23 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 01:57:23 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 02:16:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 02:16:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 02:16:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 02:16:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 02:17:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 02:17:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 02:18:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 02:18:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 02:19:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 02:19:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 02:21:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 02:21:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 02:22:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 02:22:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 02:22:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 02:22:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 02:27:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 02:27:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 02:31:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 02:31:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 02:46:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 02:46:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 03:20:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 03:20:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 03:20:17 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 03:20:17 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 03:20:27 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 03:20:27 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 03:20:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 03:20:37 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 03:56:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 03:56:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 04:20:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 04:20:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 04:21:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 04:21:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 04:21:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 04:21:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 04:21:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 04:21:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 04:54:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 04:54:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 05:18:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 05:18:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 05:26:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 05:26:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 05:27:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 05:27:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 05:27:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 05:27:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 05:27:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 05:27:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 05:29:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 05:29:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 05:30:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 05:30:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 06:04:43 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 06:04:43 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 06:20:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 06:20:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.171.0:58794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/05 06:20:42 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(order_spend_pd[\"OrderTotal\"], bins=50, color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.xlabel(\"Order Total ($)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Order Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
